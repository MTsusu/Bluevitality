#### 备忘
```txt
当数据量很大时需用到分片：
    将数据分若干部分（称分段或分片）存在不同服务器中，可将大型的集合分割保存到不同服务器上
    与其他的分区方案相比MongoDB几乎能自动为我们完成所有事情。

考虑用 Sharded cluster 时通常是要解决如下2个问题：
    1.存储容量受单机限制，即磁盘资源遭遇瓶颈
    2.读写能力受单机限制（读能力也可以在复制集里加 secondary 来扩展）可能是 CPU、内存或网卡等资源瓶颈导致读写能力无法扩展
    如果你没有遇到上述问题，使用 MongoDB 复制集就足够了，管理维护上比 Sharded cluster 要简单很多
```
#### 下图展示了在 MongoDB 中使用分片集群的结构分布模型
![shard1](资料/Shard1.png)
```txt
1.Query Routers:  前端路由，客户端由此接入并且让整个集群像是单一数据库，前端应用可透明使用（客户端无需了解其他节点存在）
2.Config Server:  元数据服务器，存储了整个 Cluster Metadata，其中包括chunk信息...
3.Shard:          存储实际数据块，生产环境中1个Shard角色可由多个节点组个1个replica set承担来防止单点故障!

    insert/request----> [mongos"路由器"] -------> [configsvr] -------> shard1.....shardN
```
#### 部署流程
```txt
可依据索引类型进行分配，但不同的索引类型其分片的方式是不同的

先启动若干mongodb服务器（shard1:100012 shard2:100013 shard1:100014）

configserver:
    ./mongod --port 10000 --dbpath /data/mongodb/shard/config  --fork --configsvr \
    --logpath log/mongodb.confserver.log --logappend
    
mongos：
    ./mongos --port 22222 --logpath log/mongodb.log  \
    --configdb <IP:port> <IP:port> <IP:port> ...  \
    --fork --chunkSize 500     #chunkSize这一项是用来指定chunk的大小的，单位是MB，默认200MB(建议使用命令方式修改大小)
   
    > use DBname;
    > sh.addShard('IP:port');				#在路由器中添加后端片节点IP/端口		查看其状态：sh.status(); ---> 可查看分片设置&状态
    > sh.enableSharding('ABC');			#允许ABC库可以被分片
    > sh.shardCollection('ABC.001',001ID);	#允许ABC库的001集合（表）可以被分片，分片时依据的列名（片键）是001ID

配置 Sharding: （注意是在mongos节点执行如下的添加块节点命令...）
    > db.runCommand({ addshard:"localhost:27020" })
    > db.runCommand({ addshard:"localhost:27020" })
    > db.runCommand({ addshard:"localhost:27020" })
    > db.runCommand({ enablesharding:"<database>" }) #设置分片存储的数据库（或：sh.enableSharding("<database>")）
    > db.runCommand({ shardcollection: "test.log", key: { id:1,time:1}})

分片方式：（需要根据业务模型进行选择）
1.基于列表分片
2.基于HASH分片
3.基于范围分片


在对一个集合分片之前，你必须开启这个集合数据库的分片功能。开启这个功能并不会重新分配数据，但能使集合能够分片。

一旦你开启了一个数据库的分片功能，MongoDB会分配一个主片，使MongoDB在分片之前将所有的数据保存在这个数据库上。


#默认chunk=64MB,其将大量文档存储在chunk中，当不同的shard中chunk使用量区别较大时将自动移动数据，有时会增加IO

手动预先分片：
for(var i=1;i<20000;i++) { sh.splitAt('库名.表名',{ID类型的列:i*10000})};	#遇到10000倍数时则进行分片（减少了IO）
```
